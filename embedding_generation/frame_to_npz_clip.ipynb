{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n",
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #exclude\n",
    "# from ffwdpy import JupNb\n",
    "# jupnb = JupNb()\n",
    "# jupnb.write_nb2py(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
       "\tif (use_tabs === undefined) {\n",
       "\t\tuse_tabs = true; \n",
       "\t}\n",
       "\n",
       "\t// apply setting to all current CodeMirror instances\n",
       "\tIPython.notebook.get_cells().map(\n",
       "\t\tfunction(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
       "\t);\n",
       "\t// make sure new CodeMirror instances created in the future also use this setting\n",
       "\tCodeMirror.defaults.indentWithTabs=use_tabs;\n",
       "\t\n",
       "\t};\n",
       "\n",
       "IPython.tab_as_tab_everywhere()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
    "\tif (use_tabs === undefined) {\n",
    "\t\tuse_tabs = true; \n",
    "\t}\n",
    "\n",
    "\t// apply setting to all current CodeMirror instances\n",
    "\tIPython.notebook.get_cells().map(\n",
    "\t\tfunction(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
    "\t);\n",
    "\t// make sure new CodeMirror instances created in the future also use this setting\n",
    "\tCodeMirror.defaults.indentWithTabs=use_tabs;\n",
    "\t\n",
    "\t};\n",
    "\n",
    "IPython.tab_as_tab_everywhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import arguments\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Arg parse function.\n",
    "def parse_args():\n",
    "\tparser = argparse.ArgumentParser(description='')\n",
    "\tparser.add_argument(\"--index\", help=\"Float Argument).\", type=float, default=0)\n",
    "\tparser.add_argument(\"--gpus\", help=\"GPU's to be used.\",\n",
    "\t\t\t\t\t\ttype=str, default=\"8\")\n",
    "\tparser.add_argument('--set', help='String Argument',\n",
    "\t\t\t\t\t\tdefault = 'training', type=str)\n",
    "\t# parser.add_argument('--set', help='String Argument',\n",
    "\t# \t\t\t\t\tdefault = 'validation', type=str)\n",
    "\n",
    "\t\n",
    "\targs = parser.parse_args()\n",
    "\treturn args\n",
    "\n",
    "# Check shell\n",
    "try:\n",
    "\tshell = get_ipython().__class__.__name__\n",
    "\tsys.argv = sys.argv[0:1]\n",
    "except:\n",
    "\tpass\n",
    "\n",
    "# Parse the args.\n",
    "args = parse_args()\n",
    "args.index = args.index % 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=args.gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fn9cAF4CA6tZ",
    "outputId": "d7664f87-79d7-4107-833a-4544ab44be34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda True\n",
      "8\n",
      "Torch version: 1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import *\n",
    "import time\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"cuda\", cuda)\n",
    "num_workers = 8 if cuda else 0\n",
    "print(num_workers)\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy7P1dQokAz4"
   },
   "source": [
    "# Load CLIP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLFS29hnhlY4",
    "outputId": "fb9c957e-23bc-4c43-9eb3-808be4b84b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliable Models:  ['RN50', 'ViT-B/32']\n",
      "Model parameters: 102,007,137\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "print(\"Avaliable Models: \", clip.available_models())\n",
    "model, preprocess = clip.load(\"RN50\", jit=False) # clip.load(\"ViT-B/32\") #\n",
    "\n",
    "input_resolution = model.input_resolution #.item()\n",
    "context_length = model.context_length #.item()\n",
    "vocab_size = model.vocab_size #.item()\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/data3/puppala/projects/Vid_CLIP/\")\n",
    "from utils.labels import labels, sub_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-161bece6c1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfzZSBWEQgJt",
    "outputId": "e0546317-c86f-4679-e1ae-c916a8d95e3b"
   },
   "outputs": [],
   "source": [
    "map_id = {}\n",
    "i=0\n",
    "for label in labels:\n",
    "\tmap_id[label]=i\n",
    "\ti+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "ROOT = \"/data3/puppala/data/kinetics_jpg/{}\".format(args.set)\n",
    "DEST = \"/data3/puppala/data/kinetics_embeddings/{}\".format(args.set)\n",
    "print(ROOT)\n",
    "print(DEST)\n",
    "cnt = 1\n",
    "for filename in labels:\n",
    "\tif filename not in os.listdir(ROOT):\n",
    "\t\tprint(filename,\" - Missing\")\n",
    "\t\t\n",
    "if args.set == 'validation':\n",
    "\tlabels = val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "vc4Ff4pKSo0O",
    "outputId": "09ca97c2-788d-4d1c-df31-c760db447562"
   },
   "outputs": [],
   "source": [
    "class_names = os.listdir(ROOT)\n",
    "len_classes = len(labels)\n",
    "split_var = np.ceil(len_classes/8)\n",
    "num_samples_per_class = 100\n",
    "print(\"Creating embeddings from {} - {}\".format(args.index * split_var, args.index*split_var + split_var))\n",
    "for cls_idx, cls_name in enumerate(labels):\n",
    "\tif cls_idx < args.index*split_var or cls_idx >= (args.index + 1)*split_var:\n",
    "\t\tcontinue\n",
    "\tclass_file = os.path.join(ROOT,cls_name)\n",
    "\trandom_tags = os.listdir(class_file)\n",
    "\tsave_dir = os.path.join(DEST, cls_name)\n",
    "\tif not os.path.exists(save_dir):\n",
    "\t\tos.makedirs(save_dir)\n",
    "\tlen_random_tags = len(random_tags)\n",
    "\tavg_time = []\n",
    "\tfor rand_id, random_tag in enumerate(random_tags):\n",
    "\t\tif rand_id >= num_samples_per_class:\n",
    "\t\t\tcontinue\n",
    "\t\ttry:\n",
    "\t\t\tstart_time = time.time()\n",
    "\t\t\tvideo_name = os.path.join(class_file,random_tag)\n",
    "\t\t\tsave_dir = os.path.join(DEST, cls_name)\n",
    "\t\t\tfile_save = os.path.join(save_dir, random_tag + '.npz')\n",
    "\t\t\tif os.path.exists(file_save):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tcount = 0\n",
    "\t\t\tframes = sorted([ x for x in os.listdir(video_name) if x.endswith('.jpg')])\n",
    "\t\t\tN = len(frames)\n",
    "\t\t\tif N >=100:\n",
    "\t\t\t\tn = N//100\n",
    "\t\t\telse:\n",
    "\t\t\t\tn = 1\n",
    "\t\t\tselected_frames = np.arange(0,N,n).tolist()[0:100]\n",
    "\t\t\timages = []\n",
    "\t\t\tfor frame in frames:\n",
    "\t\t\t\tif count in selected_frames:\n",
    "\t\t\t\t\ttmp = str(count)\n",
    "\t\t\t\t\timage = Image.open(os.path.join(video_name,frame))\n",
    "\t\t\t\t\timage = preprocess(image)\n",
    "# \t\t\t\t\timage = torch.unsqueeze(image, 0)\n",
    "\t\t\t\t\timage = image.cuda()\n",
    "\t\t\t\t\timages.append(image)\n",
    "\t\t\t\tcount+=1\n",
    "\n",
    "\t\t\timages_batch = torch.stack(images, dim=0)\n",
    "\t\t\timage_features, preattention_features = model.encode_image(images_batch , feat=True)\n",
    "# \t\t\tprint(image_features.shape, preattention_features.shape)\n",
    "\t\t\timage_features /= (image_features.norm(dim=-1, keepdim=True)  + 10e-8)\n",
    "\t\t\timage_features = image_features.detach().cpu().numpy()\n",
    "\n",
    "\t\t\tlabel = map_id[cls_name]*np.ones(image_features.shape[0])\n",
    "\t\t\tsave_dir = os.path.join(DEST, cls_name)\n",
    "\t\t\tfile_save = os.path.join(save_dir, random_tag)\n",
    "\t\t\tnp.savez(file_save, data=image_features,label=label)\n",
    "\t\t\t# np.savez(file_save + '_preattention_features', data=preattention_features.detach().cpu().numpy(), label=label)\n",
    "\t\t\tend_time = time.time()\n",
    "\t\t\tavg_time.append(end_time - start_time)\n",
    "\t\t\tprint(cls_idx - args.index*split_var, '/', np.ceil(len_classes/8), '-', rand_id, '/', \n",
    "\t\t\t\t  len_random_tags, '\\t time taken - ', np.round(np.mean(avg_time), 3), end='\\r')\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_FULL_PIPELINE_SHRITI (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
