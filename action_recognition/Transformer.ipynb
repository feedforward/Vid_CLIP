{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n",
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #exclude\n",
    "# from ffwdpy import JupNb\n",
    "# jupnb = JupNb()\n",
    "# jupnb.write_nb2py(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
       "\tif (use_tabs === undefined) {\n",
       "\t\tuse_tabs = true; \n",
       "\t}\n",
       "\n",
       "\t// apply setting to all current CodeMirror instances\n",
       "\tIPython.notebook.get_cells().map(\n",
       "\t\tfunction(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
       "\t);\n",
       "\t// make sure new CodeMirror instances created in the future also use this setting\n",
       "\tCodeMirror.defaults.indentWithTabs=use_tabs;\n",
       "\t\n",
       "\t};\n",
       "\n",
       "IPython.tab_as_tab_everywhere()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
    "\tif (use_tabs === undefined) {\n",
    "\t\tuse_tabs = true; \n",
    "\t}\n",
    "\n",
    "\t// apply setting to all current CodeMirror instances\n",
    "\tIPython.notebook.get_cells().map(\n",
    "\t\tfunction(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
    "\t);\n",
    "\t// make sure new CodeMirror instances created in the future also use this setting\n",
    "\tCodeMirror.defaults.indentWithTabs=use_tabs;\n",
    "\t\n",
    "\t};\n",
    "\n",
    "IPython.tab_as_tab_everywhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9dgq7q6AQ9n"
   },
   "source": [
    "# Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fn9cAF4CA6tZ",
    "outputId": "96aa49a1-d4ab-4501-f2e4-e6dcffdccd3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda True\n",
      "8\n",
      "Torch version: 1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import *\n",
    "import fnmatch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import clip \n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"cuda\", cuda)\n",
    "num_workers = 8 if cuda else 0\n",
    "print(num_workers)\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/data3/puppala/projects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "IfzZSBWEQgJt"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (transformer.py, line 218)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/data3/puppala/projects/Vid_CLIP/models/transformer.py\"\u001b[0;36m, line \u001b[0;32m218\u001b[0m\n\u001b[0;31m    NUM_CLASSES = 25):\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from Vid_CLIP.utils.labels import labels, val_labels, sub_labels\n",
    "from Vid_CLIP.utils.templates import imagenet_templates as templates\n",
    "from Vid_CLIP.models.transformer import Pool_Transformer_Model\n",
    "from Vid_CLIP.datasets.kinetics import Mapped_Dataset, Unmapped_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = labels\n",
    "map_id = {}\n",
    "i=0\n",
    "for classname in classnames:\n",
    "\tmap_id[classname]=i\n",
    "\ti+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model, _ = clip.load(\"RN50\") \n",
    "def zeroshot_classifier(classnames, act_descriptions):\n",
    "\twith torch.no_grad():\n",
    "\t\tzeroshot_weights = []\n",
    "\t\tfor classname in classnames:\n",
    "\t\t\ttexts = [template.format(classname) for template in templates]\n",
    "\t\t\t# pdb.set_trace()\n",
    "\t\t\ttexts = clip.tokenize(texts).cuda() #tokenize\n",
    "\t\t\tclass_embeddings = model.encode_text(texts) #embed with text encoder\n",
    "\t\t\tclass_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "\t\t\tclass_embedding = class_embeddings.mean(dim=0)\n",
    "\t\t\tclass_embedding /= class_embedding.norm()\n",
    "\t\t\tzeroshot_weights.append(class_embedding)\n",
    "\t\tzeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "\treturn zeroshot_weights\n",
    "classnames_str = {x:x.replace('_', ' ') for x in classnames}\n",
    "zeroshot_weights = zeroshot_classifier(classnames, classnames_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyS2jVIF8CEI",
    "outputId": "43379bff-b47c-46e5-97a2-76963902ab2c"
   },
   "outputs": [],
   "source": [
    "# Dataloader train\n",
    "\n",
    "val_dataset = Mapped_Dataset(\"/data3/puppala/data/kinetics_embeddings/validation\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "NUM_CLASSES = len(val_dataset.class_names)\n",
    "class_names = val_dataset.class_names\n",
    "\n",
    "train_dataset = Mapped_Dataset(\"/data3/puppala/data/kinetics_embeddings/training\" class_names = class_names)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
    "\n",
    "batch_feats,batch_labels,batch_lengths = next(iter(train_dataloader))\n",
    "print('feats - ', batch_feats.shape)\n",
    "print('labels - ', batch_labels.shape)\n",
    "print('lengths - ', batch_lengths.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyAuWGaq8Cvd"
   },
   "source": [
    "## Train and Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhvmaJyV5zp8"
   },
   "outputs": [],
   "source": [
    "# Set the hyperparameters of the model\n",
    "numEpochs = 20\n",
    "num_feats = 1024\n",
    "learningRate = 1e-3\n",
    "weightDecay = 5e-6\n",
    "num_classes = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASg7EsTG52RX"
   },
   "outputs": [],
   "source": [
    "# Model Initialisation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = Transformer_Model(ntoken=100, ninp=100, nhead=5, nhid=4, nlayers=2)\n",
    "model = Pool_Transformer_Model(spacial_dim=10, embed_dim=1024, num_heads=8, output_dim=1024)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "writer = SummaryWriter(log_dir='runs/transformer')\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def validate(model, data_loader):\n",
    "\tmodel.eval()\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\tloss = []\n",
    "\tfor batch_num, (feats,labels,lengths) in enumerate(data_loader):\n",
    "\t\tfeats,labels = feats.to(device),labels[:,0].to(device)\n",
    "\t\tout = model(feats)\n",
    "\t\tcurr_loss = criterion(out, labels.long())\n",
    "\t\tcorrect += (torch.argmax(out,dim=1)==labels).sum().detach().cpu().numpy()\n",
    "\t\ttotal += feats.shape[0]\n",
    "\t\t# Compute loss\n",
    "\t\tloss.append(curr_loss.item()) \n",
    "\n",
    "\tavg_loss = np.mean(loss)\n",
    "\tprint(\"Accuracy:\",correct/total)\n",
    "\twriter.add_scalar('Val/Loss', avg_loss) \n",
    "\twriter.add_scalar('Val/Accuracy', correct/total) \n",
    "\treturn avg_loss,correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go7rudBF5tBW"
   },
   "outputs": [],
   "source": [
    "# Train Function\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "def train(model, data_loader,numEpochs,val_dataloader):\n",
    "\tmodel.train()\n",
    "\tfor epoch in range(numEpochs):\n",
    "\t\tavg_loss = 0.0    \n",
    "\t\tfor batch_num, (feats,labels,lengths) in enumerate(data_loader):\n",
    "\t\t\ttorch.autograd.set_detect_anomaly(True)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tfeats,labels = feats.to(device),labels[:,0].to(device)\n",
    "\t\t\t# print(feats.shape)\n",
    "\t\t\tout = model(feats)\n",
    "\t\t\tloss = criterion(out, labels.long())\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()         \n",
    "\t\t\tavg_loss += loss.item()\n",
    "\t\t\tif batch_num % 50 == 49:\n",
    "\t\t\t\tprint('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))\n",
    "\t\t\t\ttrain_loss.append(avg_loss/50)\n",
    "\t\t\t\twriter.add_scalar('Train/Loss', avg_loss/50)\n",
    "\t\t\t\tavg_loss = 0.0  \n",
    "\t\t\t\tvloss,vacc = validate(model,val_dataloader)\n",
    "\t\t\t\tval_loss.append(vloss)\n",
    "\t\t\t\tval_acc.append(vacc)\n",
    "\t\t\t\tmodel.train()\n",
    "\t\tscheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "DX46hf27868-",
    "outputId": "0bc8761e-ecf0-4b80-f8c5-2238a910d614",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(model,train_dataloader,numEpochs,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIOQ0Yx05xvE"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title(\"Train and Validation Loss\")\n",
    "plt.legend(['Train Loss','Val Loss'])\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_acc)\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "_ = plt.yticks([0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_FULL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
