{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude - GPU setup\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BpdJkdBssk9",
    "outputId": "dc75b5f9-17c7-4856-ac79-8047fa609500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 11.1\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
    "print(\"CUDA version:\", CUDA_version)\n",
    "\n",
    "if CUDA_version == \"10.0\":\n",
    "    torch_version_suffix = \"+cu100\"\n",
    "elif CUDA_version == \"10.1\":\n",
    "    torch_version_suffix = \"+cu101\"\n",
    "elif CUDA_version == \"10.2\":\n",
    "    torch_version_suffix = \"\"\n",
    "else:\n",
    "    torch_version_suffix = \"+cu110\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBVr18E5tse8",
    "outputId": "404230c1-0f78-451d-8816-19d4109d579e"
   },
   "outputs": [],
   "source": [
    "# ! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
    "\n",
    "# The following command installs the `clip` module from its source:\n",
    " # ! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1hkDT38hSaP",
    "outputId": "6cd33e12-aed4-4950-e32f-6f1113eb3ade"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFxgLV5HAEEw"
   },
   "source": [
    "# Loading the model\n",
    "\n",
    "Download and instantiate a CLIP model using the `clip` module that we just installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLFS29hnhlY4",
    "outputId": "3148f942-0226-42a3-e5d8-4b9bc6c7c4f8"
   },
   "outputs": [],
   "source": [
    "print(\"Avaliable Models: \", clip.available_models())\n",
    "model, preprocess = clip.load(\"ViT-B/32\") #clip.load(\"RN50\", jit=False) #\n",
    "\n",
    "input_resolution = model.input_resolution #.item()\n",
    "context_length = model.context_length #.item()\n",
    "vocab_size = model.vocab_size #.item()\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2HbOZrqa0jF"
   },
   "outputs": [],
   "source": [
    "# Load inputs\n",
    "act_map = {}\n",
    "with open(\"../../../act_idx_to_name_new.txt\") as f:\n",
    "\tfor line in f:\n",
    "\t\t(key, val) = line.split()\n",
    "\t\tact_map[int(key)] = val\n",
    "\n",
    "with open(\"../../../activity_descriptions.txt\", 'r') as f:\n",
    "    act_des = f.readlines()\n",
    "\n",
    "act_dict = {}\n",
    "for i in range(len(act_des)//2):\n",
    "    act_dict[act_des[2*i].strip()] = act_des[2*i + 1].strip()\n",
    "    \n",
    "classnames = [act_map[i] for i in range(1, 38)]#sorted(list(act_dict.keys()))\n",
    "classnames_str = {x:x.replace('_', ' ') for x in classnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_act_map = {val:key for key, val in act_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4kPSZoShQxN"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4e3a3f83649f45f8bef3434980634664",
      "f066bdb766664c788ba1e9de8d311e22",
      "4e7a7427d28a4ae684e0be4548eb9944",
      "cc9dc019c1334a46b2558ffa6c0dd6e6",
      "285c877d4f644f3a8a58c4eb5948101c",
      "075d6545e02e419ca565589eb5ffc318",
      "53f9106c80e84d5b8c3ec96162d1db98",
      "19c57d99e7c44cbda508ce558fde435d"
     ]
    },
    "id": "sRqDoz1Gbsii",
    "outputId": "5ab6c001-8a5e-42c9-ab46-4477a693229c"
   },
   "outputs": [],
   "source": [
    "def zeroshot_classifier(classnames, act_descriptions):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        for classname in tqdm(classnames):\n",
    "            des_size = len(act_descriptions[classname])\n",
    "            texts =  [ act_descriptions[classname][x : x+100] for x in range(0, des_size, 100)]#format with class\n",
    "            # print(\"\\n\\n\".join(texts), \"\\n###################################\\n\")\n",
    "            texts = clip.tokenize(texts).cuda() #tokenize\n",
    "            # print(texts.shape, \"\\n###################################\\n\")\n",
    "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            \n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "    return zeroshot_weights\n",
    "\n",
    "\n",
    "zeroshot_weights = zeroshot_classifier(classnames, act_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = np.load('data.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEVA.code.utils.vattr import VAttr, MAttr\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mattr = MAttr(\"\")\n",
    "vattr = VAttr(mdata[0]['Video_Path'][5:], mattr = mattr)\n",
    "count = 0\n",
    "images_full = []\n",
    "targets = []\n",
    "logits_full = []\n",
    "top1, top3, top5, n = 0., 0., 0., 0.\n",
    "with torch.no_grad():\n",
    "    for key, val in mdata.items():\n",
    "        vattr.set_vidname(val['Video_Path'][5:])\n",
    "        frame_path = vattr.frame_path\n",
    "        start_frame = int(val['Start_Frame'])\n",
    "        end_frame = int(val['End_Frame'])\n",
    "        mid_frame = (end_frame + start_frame)//2\n",
    "        bbox = val['BBox']\n",
    "        for i in range(mid_frame-2, mid_frame+ 3):\n",
    "            if  not os.path.exists(frame_path): continue\n",
    "            \n",
    "            full_path = os.path.join(frame_path, '{0:06}.jpg'.format(i))\n",
    "            try:\n",
    "                img =  Image.open(full_path)\n",
    "            except:\n",
    "                continue\n",
    "            img2 = img.crop(tuple(bbox))\n",
    "            images = preprocess(img2)\n",
    "            images_full.append(images)\n",
    "            images = torch.unsqueeze(images, 0)\n",
    "            target = torch.Tensor([val['Activity_Id'] - 1])\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "            image_features = model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            logits = 100. * image_features @ zeroshot_weights\n",
    "            acc1, acc3, acc5 = accuracy(logits, target, topk=(1, 3, 5))\n",
    "            top1 += acc1\n",
    "            top3 += acc3\n",
    "            top5 += acc5\n",
    "            n += 1\n",
    "            logits_full.append(logits)\n",
    "            targets.append(val['Activity_Id']- 1)\n",
    "            count+= 1\n",
    "            print(count, end='\\r')\n",
    "top1 = (top1 / n) * 100\n",
    "top3 = (top3 / n) * 100\n",
    "top5 = (top5 / n) * 100 \n",
    "\n",
    "print(f\"Top-1 accuracy: {top1:.2f}\")\n",
    "print(f\"Top-3 accuracy: {top3:.2f}\")\n",
    "print(f\"Top-5 accuracy: {top5:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [np.argmax(x.cpu().numpy()) for x in logits_full]\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "bins = np.arange(1,38)\n",
    "plt.hist([targets, preds] , bins=37, range=(1,38), label=['gt', 'preds'])\n",
    "plt.legend(loc='upper right')\n",
    "# plt.gca().set_xticks(classnames)\n",
    "_ = plt.xticks(bins+0.5, classnames, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fZo7hG8iJP5"
   },
   "source": [
    "# Zero-shot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [1/0.26862954, 1/0.26130258, 1/0.27577711]),\n",
    "                                transforms.Normalize(mean = [-0.48145466, -0.4578275, -0.40821073],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "fbb2b937b22049f5987f39f48c652a86",
      "0a1b6b76984349ccb36ca2fc4a4a0208",
      "c136afb47aa14ac2832093ee415c6f3e",
      "467a151e73744eccb199fe72aa352e5b",
      "f6d637c3fc3c46928d023441227130e5",
      "029e6eadacb8480193aab52ff073be8f",
      "30178355f76742898d37966b3875ef0a",
      "2e62544c03d64d6d92b94fcfaca2fc90"
     ]
    },
    "id": "wKJ7YsdlkDXo",
    "outputId": "90e084fd-86bc-4a52-a06e-61bff7aa86e0"
   },
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "with torch.no_grad():\n",
    "    top1, top5, n = 0., 0., 0.\n",
    "    for i, (images, target) in enumerate(tqdm(loader)):\n",
    "        images = images.cuda()\n",
    "        target = target.cuda()\n",
    "        \n",
    "        # predict\n",
    "        image_features, attention_weights = model.encode_image(images, feat=True)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        logits = 100. * image_features @ zeroshot_weights\n",
    "        preds = np.argmax(logits.cpu().detach().numpy(), axis=-1)\n",
    "        visualize(images, attention_weights, i, target, preds)\n",
    "\n",
    "        # measure accuracy\n",
    "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
    "        top1 += acc1\n",
    "        top5 += acc5\n",
    "        n += images.size(0)\n",
    "\n",
    "top1 = (top1 / n) * 100\n",
    "top5 = (top5 / n) * 100 \n",
    "\n",
    "print(f\"Top-1 accuracy: {top1:.2f}\")\n",
    "print(f\"Top-5 accuracy: {top5:.2f}\")\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(images, attention_weights, batch_id, target, preds):\n",
    "\n",
    "    img_viz = invTrans(images).cpu().numpy().transpose((0, 2,3, 1))\n",
    "    attention_weights = attention_weights.detach().cpu().numpy()\n",
    "    num_images = a.shape[0]\n",
    "\n",
    "    for idx in range(num_images):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plt.subplot(2,2, 1)\n",
    "        plt.imshow(img_viz[idx])\n",
    "        plt.title(imagenet_classes[target[idx]])\n",
    "\n",
    "        att_map = attention_weights[idx][:49].reshape(7,7).astype(np.float32)\n",
    "        plt.subplot(2,2, 2)\n",
    "        plt.imshow(att_map)\n",
    "        plt.title(imagenet_classes[preds[idx]])\n",
    "\n",
    "        att_map_resized = cv2.resize(att_map, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        att_map_resized= att_map_resized\n",
    "        plt.subplot(2,2, 3)\n",
    "        plt.imshow(att_map_resized)\n",
    "\n",
    "        frame = img_viz[idx]\n",
    "        heatmap = att_map_resized #cv2.cvtColor(att_map_resized, cv2.COLOR_GRAY2RGB)\n",
    "        heatmapshow = None\n",
    "        heatmapshow = cv2.normalize(heatmap, heatmapshow, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        heatmapshow = cv2.applyColorMap(heatmapshow, cv2.COLORMAP_JET)\n",
    "        heatmapshow = heatmapshow.astype(np.float32)/255\n",
    "        alpha = 0.4 # set convering image transparency \n",
    "        frame = cv2.addWeighted(heatmapshow, alpha, frame, 1-alpha, 0) # overlap background with original image\n",
    "        plt.subplot(2,2, 4)\n",
    "        plt.imshow(frame)\n",
    "        plt.savefig(\"visuals/{}_{}.png\".format(batch_id, idx), bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Prompt Engineering for ImageNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "029e6eadacb8480193aab52ff073be8f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "075d6545e02e419ca565589eb5ffc318": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a1b6b76984349ccb36ca2fc4a4a0208": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19c57d99e7c44cbda508ce558fde435d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285c877d4f644f3a8a58c4eb5948101c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2e62544c03d64d6d92b94fcfaca2fc90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30178355f76742898d37966b3875ef0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "467a151e73744eccb199fe72aa352e5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e62544c03d64d6d92b94fcfaca2fc90",
      "placeholder": "​",
      "style": "IPY_MODEL_30178355f76742898d37966b3875ef0a",
      "value": " 313/313 [01:26&lt;00:00,  3.62it/s]"
     }
    },
    "4e3a3f83649f45f8bef3434980634664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e7a7427d28a4ae684e0be4548eb9944",
       "IPY_MODEL_cc9dc019c1334a46b2558ffa6c0dd6e6"
      ],
      "layout": "IPY_MODEL_f066bdb766664c788ba1e9de8d311e22"
     }
    },
    "4e7a7427d28a4ae684e0be4548eb9944": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_075d6545e02e419ca565589eb5ffc318",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_285c877d4f644f3a8a58c4eb5948101c",
      "value": 1000
     }
    },
    "53f9106c80e84d5b8c3ec96162d1db98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c136afb47aa14ac2832093ee415c6f3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_029e6eadacb8480193aab52ff073be8f",
      "max": 313,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6d637c3fc3c46928d023441227130e5",
      "value": 313
     }
    },
    "cc9dc019c1334a46b2558ffa6c0dd6e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19c57d99e7c44cbda508ce558fde435d",
      "placeholder": "​",
      "style": "IPY_MODEL_53f9106c80e84d5b8c3ec96162d1db98",
      "value": " 1000/1000 [01:09&lt;00:00, 14.35it/s]"
     }
    },
    "f066bdb766664c788ba1e9de8d311e22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6d637c3fc3c46928d023441227130e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fbb2b937b22049f5987f39f48c652a86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c136afb47aa14ac2832093ee415c6f3e",
       "IPY_MODEL_467a151e73744eccb199fe72aa352e5b"
      ],
      "layout": "IPY_MODEL_0a1b6b76984349ccb36ca2fc4a4a0208"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
