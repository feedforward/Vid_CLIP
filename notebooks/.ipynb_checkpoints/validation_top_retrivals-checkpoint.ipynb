{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n",
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook activity_proposal_classification_top_retrivals.ipynb to python\n",
      "[NbConvertApp] Writing 11369 bytes to activity_proposal_classification_top_retrivals.py\n"
     ]
    }
   ],
   "source": [
    "#exclude\n",
    "from ffwdpy import JupNb\n",
    "jupnb = JupNb()\n",
    "jupnb.write_nb2py(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "\n",
    "IPython.tab_as_tab_everywhere = function(use_tabs) {\n",
    "\tif (use_tabs === undefined) {\n",
    "\t\tuse_tabs = true; \n",
    "\t}\n",
    "\n",
    "\t// apply setting to all current CodeMirror instances\n",
    "\tIPython.notebook.get_cells().map(\n",
    "\t\tfunction(c) {  return c.code_mirror.options.indentWithTabs=use_tabs;  }\n",
    "\t);\n",
    "\t// make sure new CodeMirror instances created in the future also use this setting\n",
    "\tCodeMirror.defaults.indentWithTabs=use_tabs;\n",
    "\t\n",
    "\t};\n",
    "\n",
    "IPython.tab_as_tab_everywhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU setup\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BpdJkdBssk9",
    "outputId": "dc75b5f9-17c7-4856-ac79-8047fa609500"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
    "print(\"CUDA version:\", CUDA_version)\n",
    "\n",
    "if CUDA_version == \"10.0\":\n",
    "    torch_version_suffix = \"+cu100\"\n",
    "elif CUDA_version == \"10.1\":\n",
    "    torch_version_suffix = \"+cu101\"\n",
    "elif CUDA_version == \"10.2\":\n",
    "    torch_version_suffix = \"\"\n",
    "else:\n",
    "    torch_version_suffix = \"+cu110\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBVr18E5tse8",
    "outputId": "404230c1-0f78-451d-8816-19d4109d579e"
   },
   "outputs": [],
   "source": [
    "# ! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
    "\n",
    "# The following command installs the `clip` module from its source:\n",
    " # ! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1hkDT38hSaP",
    "outputId": "6cd33e12-aed4-4950-e32f-6f1113eb3ade"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import clip\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFxgLV5HAEEw"
   },
   "source": [
    "# Loading the model\n",
    "\n",
    "Download and instantiate a CLIP model using the `clip` module that we just installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLFS29hnhlY4",
    "outputId": "3148f942-0226-42a3-e5d8-4b9bc6c7c4f8"
   },
   "outputs": [],
   "source": [
    "print(\"Avaliable Models: \", clip.available_models())\n",
    "model, preprocess = clip.load(\"RN50\") # clip.load(\"ViT-B/32\") #\n",
    "\n",
    "input_resolution = model.input_resolution #.item()\n",
    "context_length = model.context_length #.item()\n",
    "vocab_size = model.vocab_size #.item()\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2HbOZrqa0jF"
   },
   "outputs": [],
   "source": [
    "# Load inputs\n",
    "act_map = {}\n",
    "with open(\"../../../act_idx_to_name_new.txt\") as f:\n",
    "\tfor line in f:\n",
    "\t\t(key, val) = line.split()\n",
    "\t\tact_map[int(key)] = val\n",
    "\n",
    "with open(\"../../../activity_descriptions.txt\", 'r') as f:\n",
    "    act_des = f.readlines()\n",
    "\n",
    "act_dict = {}\n",
    "for i in range(len(act_des)//2):\n",
    "    act_dict[act_des[2*i].strip()] = act_des[2*i + 1].strip()\n",
    "    \n",
    "classnames = [act_map[i] for i in range(1, 38)]#sorted(list(act_dict.keys()))\n",
    "classnames_str = {x:x.replace('_', ' ') for x in classnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'a bad photo of a {}.',\n",
    "    'a photo of many {}.',\n",
    "    'a sculpture of a {}.',\n",
    "    'a photo of the hard to see {}.',\n",
    "    'a low resolution photo of the {}.',\n",
    "    'a rendering of a {}.',\n",
    "    'graffiti of a {}.',\n",
    "    'a bad photo of the {}.',\n",
    "    'a cropped photo of the {}.',\n",
    "    'a tattoo of a {}.',\n",
    "    'the embroidered {}.',\n",
    "    'a photo of a hard to see {}.',\n",
    "    'a bright photo of a {}.',\n",
    "    'a photo of a clean {}.',\n",
    "    'a photo of a dirty {}.',\n",
    "    'a dark photo of the {}.',\n",
    "    'a drawing of a {}.',\n",
    "    'a photo of my {}.',\n",
    "    'the plastic {}.',\n",
    "    'a photo of the cool {}.',\n",
    "    'a close-up photo of a {}.',\n",
    "    'a black and white photo of the {}.',\n",
    "    'a painting of the {}.',\n",
    "    'a painting of a {}.',\n",
    "    'a pixelated photo of the {}.',\n",
    "    'a sculpture of the {}.',\n",
    "    'a bright photo of the {}.',\n",
    "    'a cropped photo of a {}.',\n",
    "    'a plastic {}.',\n",
    "    'a photo of the dirty {}.',\n",
    "    'a jpeg corrupted photo of a {}.',\n",
    "    'a blurry photo of the {}.',\n",
    "    'a photo of the {}.',\n",
    "    'a good photo of the {}.',\n",
    "    'a rendering of the {}.',\n",
    "    'a {} in a video game.',\n",
    "    'a photo of one {}.',\n",
    "    'a doodle of a {}.',\n",
    "    'a close-up photo of the {}.',\n",
    "    'a photo of a {}.',\n",
    "    'the origami {}.',\n",
    "    'the {} in a video game.',\n",
    "    'a sketch of a {}.',\n",
    "    'a doodle of the {}.',\n",
    "    'a origami {}.',\n",
    "    'a low resolution photo of a {}.',\n",
    "    'the toy {}.',\n",
    "    'a rendition of the {}.',\n",
    "    'a photo of the clean {}.',\n",
    "    'a photo of a large {}.',\n",
    "    'a rendition of a {}.',\n",
    "    'a photo of a nice {}.',\n",
    "    'a photo of a weird {}.',\n",
    "    'a blurry photo of a {}.',\n",
    "    'a cartoon {}.',\n",
    "    'art of a {}.',\n",
    "    'a sketch of the {}.',\n",
    "    'a embroidered {}.',\n",
    "    'a pixelated photo of a {}.',\n",
    "    'itap of the {}.',\n",
    "    'a jpeg corrupted photo of the {}.',\n",
    "    'a good photo of a {}.',\n",
    "    'a plushie {}.',\n",
    "    'a photo of the nice {}.',\n",
    "    'a photo of the small {}.',\n",
    "    'a photo of the weird {}.',\n",
    "    'the cartoon {}.',\n",
    "    'art of the {}.',\n",
    "    'a drawing of the {}.',\n",
    "    'a photo of the large {}.',\n",
    "    'a black and white photo of a {}.',\n",
    "    'the plushie {}.',\n",
    "    'a dark photo of a {}.',\n",
    "    'itap of a {}.',\n",
    "    'graffiti of the {}.',\n",
    "    'a toy {}.',\n",
    "    'itap of my {}.',\n",
    "    'a photo of a cool {}.',\n",
    "    'a photo of a small {}.',\n",
    "    'a tattoo of the {}.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_act_map = {val:key for key, val in act_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.26862954, 1/0.26130258, 1/0.27577711]),\n",
    "                                transforms.Normalize(mean = [ -0.48145466, -0.4578275, -0.40821073 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4kPSZoShQxN"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4e3a3f83649f45f8bef3434980634664",
      "f066bdb766664c788ba1e9de8d311e22",
      "4e7a7427d28a4ae684e0be4548eb9944",
      "cc9dc019c1334a46b2558ffa6c0dd6e6",
      "285c877d4f644f3a8a58c4eb5948101c",
      "075d6545e02e419ca565589eb5ffc318",
      "53f9106c80e84d5b8c3ec96162d1db98",
      "19c57d99e7c44cbda508ce558fde435d"
     ]
    },
    "id": "sRqDoz1Gbsii",
    "outputId": "5ab6c001-8a5e-42c9-ab46-4477a693229c"
   },
   "outputs": [],
   "source": [
    "def zeroshot_classifier(classnames, act_descriptions):\n",
    "    with torch.no_grad():\n",
    "        zeroshot_weights = []\n",
    "        for classname in tqdm(classnames):\n",
    "            #print(classname, act_descriptions[classname])\n",
    "            des_size = len(act_descriptions[classname])\n",
    "            texts =  [ act_descriptions[classname][x : x+100] for x in range(0, des_size, 100)]#format with class\n",
    "            texts = [template.format(texts[0]) for template in templates]\n",
    "            # print(\"\\n\\n\".join(texts), \"\\n###################################\\n\")\n",
    "            texts = clip.tokenize(texts).cuda() #tokenize\n",
    "            # print(texts.shape, \"\\n###################################\\n\")\n",
    "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=0)\n",
    "            \n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
    "    return zeroshot_weights\n",
    "\n",
    "\n",
    "zeroshot_weights = zeroshot_classifier(classnames, classnames_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata = np.load('data.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEVA.code.utils.vattr import VAttr, MAttr\n",
    "from PIL import Image\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mattr = MAttr(\"\")\n",
    "vattr = VAttr(mdata[0]['Video_Path'][5:], mattr = mattr)\n",
    "count = 0\n",
    "targets = []\n",
    "logits_full = []\n",
    "probs_full = []\n",
    "img_full = []\n",
    "maj_vote = 0.0\n",
    "tot_vids = 0.0\n",
    "top1, top3, top5, n = 0., 0., 0., 0.\n",
    "with torch.no_grad():\n",
    "\tfor key, val in mdata.items():\n",
    "\t\tvattr.set_vidname(val['Video_Path'][5:])\n",
    "\t\tframe_path = vattr.frame_path\n",
    "\t\tstart_frame = int(val['Start_Frame'])\n",
    "\t\tend_frame = int(val['End_Frame'])\n",
    "\t\tmid_frame = (end_frame + start_frame)//2\n",
    "\t\tbbox = val['BBox']\n",
    "\t\tvid_pred = []\n",
    "\t\tfor i in range(start_frame, end_frame+ 3):\n",
    "\t\t\tif  not os.path.exists(frame_path): continue\n",
    "\n",
    "\t\t\tfull_path = os.path.join(frame_path, '{0:06}.jpg'.format(i))\n",
    "\t\t\ttry:\n",
    "\t\t\t\timg =  Image.open(full_path)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg2 = img.crop(tuple(bbox))\n",
    "\t\t\timages = preprocess(img2)\n",
    "\t\t\timg_full.append(images)\n",
    "\t\t\timages = torch.unsqueeze(images, 0)\n",
    "\t\t\ttarget = torch.Tensor([val['Activity_Id'] - 1])\n",
    "\t\t\timages = images.cuda()\n",
    "\t\t\ttarget = target.cuda()\n",
    "\t\t\timage_features = model.encode_image(images)\n",
    "\t\t\timage_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\t\t\tlogits = 100. * image_features @ zeroshot_weights\n",
    "\t\t\tprobs = logits.softmax(dim=-1)\n",
    "\t\t\tprobs = probs.type(torch.DoubleTensor)\n",
    "\t\t\ttop_probs, top_labels = probs.cpu().topk(5, dim=-1)\n",
    "\t\t\tvid_pred.append(top_labels[0][0].numpy())\n",
    "\t\t\tacc1, acc3, acc5 = accuracy(logits, target, topk=(1, 3, 5))\n",
    "\t\t\ttop1 += acc1\n",
    "\t\t\ttop3 += acc3\n",
    "\t\t\ttop5 += acc5\n",
    "\t\t\tn += 1\n",
    "\t\t\tprobs_full.append(probs[0].cpu().numpy())\n",
    "\t\t\tlogits_full.append(logits[0].cpu().numpy())\n",
    "\t\t\ttargets.append(val['Activity_Id'] - 1)\n",
    "\t\t\tcount+= 1\n",
    "\t\t\tprint(count, end='\\r')\n",
    "\t\tvid_pred = np.array(vid_pred)\n",
    "\t\tif (vid_pred.shape[0]):\n",
    "\t\t\tmaj_vote += (stats.mode(vid_pred)[0][0] == (val['Activity_Id'] - 1))\n",
    "\t\t\ttot_vids += 1\n",
    "\t\t# if (count > 10 ): break\n",
    "top1 = (top1 / n) * 100\n",
    "top3 = (top3 / n) * 100\n",
    "top5 = (top5 / n) * 100 \n",
    "maj_vote = (maj_vote/tot_vids) * 100\n",
    "print(f\"Top-1 accuracy: {top1:.2f}\")\n",
    "print(f\"Top-3 accuracy: {top3:.2f}\")\n",
    "print(f\"Top-5 accuracy: {top5:.2f}\")\n",
    "print(f\"Maj Vote Top-1 accuracy: {maj_vote:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_full_arr = np.array(probs_full)\n",
    "top_10_incides = {}\n",
    "for i in range(0, 37):\n",
    "\ttop_10_incides[i] = probs_full_arr[:, i].argsort()[-10:][::-1]\n",
    "\n",
    "for i in range(0, 37):\n",
    "\tfig = plt.figure(figsize=(20, 5))\n",
    "\tfor j in range(10):\n",
    "\t\tplt.subplot(1, 10, j + 1)\n",
    "\t\tk = top_10_incides[i][j]\n",
    "\t\tinv_tensor = invTrans(img_full[k])\n",
    "\t\tplt.imshow(inv_tensor.cpu().numpy().transpose(1,2,0))\n",
    "\t\tax = plt.gca()\n",
    "\t\tax.axes.xaxis.set_visible(False)\n",
    "\t\tax.axes.yaxis.set_visible(False)\n",
    "\tplt.title(classnames[i])\n",
    "\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [np.argmax(x.cpu().numpy()) for x in logits_full]\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "bins = np.arange(0,37)\n",
    "plt.hist([targets, preds] , bins=37, range=(0,37), label=['gt', 'preds'])\n",
    "plt.legend(loc='upper right')\n",
    "# plt.gca().set_xticks(classnames)\n",
    "_ = plt.xticks(bins+0.5, classnames, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "cm = confusion_matrix(targets, preds, labels = np.arange(0, 37), normalize='true')\n",
    "df = pd.DataFrame(cm, index=classnames, columns=classnames)\n",
    "plt.figure(figsize=(10,10))\n",
    "sn.set(font_scale=1) # for label size\n",
    "sn.heatmap(df)#, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "out = cosine_similarity(zeroshot_weights.T.cpu().numpy())\n",
    "df = pd.DataFrame(out, index=classnames, columns=classnames)\n",
    "plt.figure(figsize=(20,20))\n",
    "sn.set(font_scale=1) # for label size\n",
    "sn.heatmap(df)#, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Prompt Engineering for ImageNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "029e6eadacb8480193aab52ff073be8f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "075d6545e02e419ca565589eb5ffc318": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a1b6b76984349ccb36ca2fc4a4a0208": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19c57d99e7c44cbda508ce558fde435d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285c877d4f644f3a8a58c4eb5948101c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2e62544c03d64d6d92b94fcfaca2fc90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30178355f76742898d37966b3875ef0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "467a151e73744eccb199fe72aa352e5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e62544c03d64d6d92b94fcfaca2fc90",
      "placeholder": "​",
      "style": "IPY_MODEL_30178355f76742898d37966b3875ef0a",
      "value": " 313/313 [01:26&lt;00:00,  3.62it/s]"
     }
    },
    "4e3a3f83649f45f8bef3434980634664": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e7a7427d28a4ae684e0be4548eb9944",
       "IPY_MODEL_cc9dc019c1334a46b2558ffa6c0dd6e6"
      ],
      "layout": "IPY_MODEL_f066bdb766664c788ba1e9de8d311e22"
     }
    },
    "4e7a7427d28a4ae684e0be4548eb9944": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_075d6545e02e419ca565589eb5ffc318",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_285c877d4f644f3a8a58c4eb5948101c",
      "value": 1000
     }
    },
    "53f9106c80e84d5b8c3ec96162d1db98": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c136afb47aa14ac2832093ee415c6f3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_029e6eadacb8480193aab52ff073be8f",
      "max": 313,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6d637c3fc3c46928d023441227130e5",
      "value": 313
     }
    },
    "cc9dc019c1334a46b2558ffa6c0dd6e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19c57d99e7c44cbda508ce558fde435d",
      "placeholder": "​",
      "style": "IPY_MODEL_53f9106c80e84d5b8c3ec96162d1db98",
      "value": " 1000/1000 [01:09&lt;00:00, 14.35it/s]"
     }
    },
    "f066bdb766664c788ba1e9de8d311e22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6d637c3fc3c46928d023441227130e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fbb2b937b22049f5987f39f48c652a86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c136afb47aa14ac2832093ee415c6f3e",
       "IPY_MODEL_467a151e73744eccb199fe72aa352e5b"
      ],
      "layout": "IPY_MODEL_0a1b6b76984349ccb36ca2fc4a4a0208"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
